# -*- coding: utf-8 -*-
"""iic2.0

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/11qdpxE6wKncCr7OCr8sYKBi-79qslZjJ
"""

X = np.concatenate([student_vec[history["s_idx"]].toarray(), internship_vec[history["j_idx"]].toarray()], axis=1)
y = history["applied"]

print(student_vec.shape)
print(internship_vec.shape)

X = np.concatenate([student_vec[history["s_idx"]].toarray(), internship_vec[history["j_idx"]].toarray()], axis=1)
y = history["applied"]

X = np.concatenate([student_vec[history["s_idx"]].toarray(), internship_vec[history["j_idx"]].toarray()], axis=1)
y = history["applied"]

print(X.shape)
print(y.shape)

from sklearn.neighbors import KNeighborsClassifier

best_knn_phi = KNeighborsClassifier()
best_knn_phi.fit(X, y)

best_knn_sw = KNeighborsClassifier()
best_knn_sw.fit(X, y)

from xgboost import XGBClassifier

best_xgb_phi = XGBClassifier()
best_xgb_phi.fit(X, y)

best_xgb_sw = XGBClassifier()
best_xgb_sw.fit(X, y)

from xgboost import XGBClassifier

best_xgb_phi = XGBClassifier()
best_xgb_phi.fit(X, y)

best_xgb_sw = XGBClassifier()
best_xgb_sw.fit(X, y)

import pandas as pd
import numpy as np
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
from xgboost import XGBClassifier
import joblib
import random
import plotly.graph_objects as go
from plotly.subplots import make_subplots


students = pd.read_csv("students_dataset.csv")
internships = pd.read_csv("internships_dataset.csv")

students["student_id"] = students["student_id"].astype(str).str.strip().str.upper()
internships["internship_id"] = internships["internship_id"].astype(str).str.strip().str.upper()

if "required_CGPA" not in internships.columns:
    internships["required_CGPA"] = np.random.uniform(6.0, 9.0, size=len(internships))


tfidf = TfidfVectorizer(stop_words="english")
internship_vec = tfidf.fit_transform(internships["required_skills"])
student_vec = tfidf.transform(students["skills"])

content_scores = cosine_similarity(student_vec, internship_vec)


history = []
for s in students["student_id"].sample(300, random_state=42):
    for j in internships["internship_id"].sample(20, random_state=42):
        applied = random.choice([0, 1])
        history.append([s, j, applied])
history = pd.DataFrame(history, columns=["student_id", "internship_id", "applied"])

map_students = {id_: idx for idx, id_ in enumerate(students["student_id"])}
map_internships = {id_: idx for idx, id_ in enumerate(internships["internship_id"])}

history["s_idx"] = history["student_id"].map(map_students)
history["j_idx"] = history["internship_id"].map(map_internships)

ratings = np.zeros((len(students), len(internships)))
for row in history.itertuples():
    ratings[row.s_idx, row.j_idx] = row.applied

sim_students = cosine_similarity(ratings)
sim_internships = cosine_similarity(ratings.T)


def check_eligibility(student_id):
    student_row = students[students["student_id"] == student_id]
    if student_row.empty:
        return []
    student = student_row.iloc[0]

    eligible_ids = []
    for _, intern in internships.iterrows():
        if student["cgpa"] < intern["required_CGPA"]:
            continue

        sector_degree_map = {
            "IT": ["B.TECH", "M.TECH", "B.SC CS", "MCA"],
            "FINANCE": ["B.COM", "MBA", "CA"],
            "HR": ["MBA", "BBA"],
            "RESEARCH": ["M.SC", "PHD", "M.TECH"],
            "MARKETING": ["MBA", "BBA"],
            "HEALTHCARE": ["B.TECH", "M.TECH"],
            "MANAGEMENT": ["MBA", "BBA"],
            "EDUCATION": ["B.ED", "M.ED"]
        }
        if str(student["degree"]).upper() not in sector_degree_map.get(str(intern["sector"]).upper(), []):
            continue

        if intern["location"] != "Remote" and student["location"] != intern["location"]:
            continue
        if intern["location"] == "Remote" and student["preference_remote"] == False:
            continue

        eligible_ids.append(intern["internship_id"])

    return eligible_ids


def internship_dashboard(student_id, top_n=5):
    if student_id not in map_students:
        print("❌ Student ID not found.")
        return

    eligible_ids = check_eligibility(student_id)
    if not eligible_ids:
        print("❌ No eligible internships for this student.")
        return

    s_idx = map_students[student_id]
    eligible_internships = internships[internships["internship_id"].isin(eligible_ids)]
    eligible_vec = tfidf.transform(eligible_internships["required_skills"])

    student_vector = student_vec[s_idx]
    content_scores_filtered = cosine_similarity(student_vector, eligible_vec).flatten()
    top_indices = content_scores_filtered.argsort()[::-1][:top_n]

    recs = eligible_internships.iloc[top_indices][["internship_id","title","sector","location","required_skills"]].copy()
    recs["score"] = content_scores_filtered[top_indices]

    print(f"\n📌 Top {top_n} Recommendations for {student_id}:")
    print(recs[["title","sector","location","score"]])


def profile_insight(student_id):
    student_row_df = students[students["student_id"] == student_id]
    if student_row_df.empty:
        print(f"❌ Student ID '{student_id}' not found.")
        return

    student = student_row_df.iloc[0]
    student_skills = set(str(student["skills"]).split(", "))
    all_skills = set()
    for _, intern in internships.iterrows():
        skills = set(str(intern["required_skills"]).split(", "))
        all_skills.update(skills)

    matched_skills = student_skills.intersection(all_skills)
    skill_score = len(matched_skills) / len(all_skills) * 100 if all_skills else 0

    fields = ["skills", "cgpa", "degree", "location", "preference_remote"]
    filled = sum([1 for f in fields if pd.notna(student.get(f))])
    completeness = filled / len(fields) * 100

    missing_skills = all_skills - student_skills
    course_suggestions = [f"Course on {s}" for s in list(missing_skills)[:10]]
    improvement = len(course_suggestions) / max(len(missing_skills), 1) * 100

    overall = 0.5 * skill_score + 0.3 * completeness + 0.2 * improvement

    fig = go.Figure(go.Indicator(
        mode="gauge+number+delta",
        value=overall,
        delta={'reference': 50},
        title={'text': "Overall Profile Score"},
        gauge={'axis': {'range': [0, 100]},
               'bar': {'color': "teal"},
               'steps': [
                   {'range': [0, 50], 'color': "red"},
                   {'range': [50, 75], 'color': "yellow"},
                   {'range': [75, 100], 'color': "green"}]})
    )
    fig.show()

    print(f"Skill Score: {skill_score:.2f}%")
    print(f"Profile Completeness: {completeness:.2f}%")
    print(f"Improvement Potential: {improvement:.2f}%")
    print(f"Overall Profile Score: {overall:.2f}%")


print("Sample student IDs:", students["student_id"].head(10).tolist())
profile_insight("S00006")
internship_dashboard("S00006", top_n=5)

def get_recommendations(student_id):
    # fetch student data from MySQL
    # run eligibility + recommendation model
    return recommended_internships